{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Conv1D, AveragePooling1D, MaxPooling1D, Dropout, Embedding, LSTM, Dense, Bidirectional, TimeDistributed, concatenate, Flatten, BatchNormalization\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import add\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../real_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        DSMQYTYKIV\n",
       "1         SLLKYFFVL\n",
       "2        ILYVPMSLSM\n",
       "3         NQLLARPFL\n",
       "4         AEMEKEGKI\n",
       "5         IYFEKNKTL\n",
       "6          VNFVCQRV\n",
       "7         CPILSTINI\n",
       "8         VCYYLLMHL\n",
       "9          SIIRFEKL\n",
       "10       CSNIQYGYKI\n",
       "11      ISQILSKTIAL\n",
       "12        NNLVKWPLL\n",
       "13       DFFPDLNALV\n",
       "14        LPSLPIFDI\n",
       "15       KFPTNTLTSI\n",
       "16       DVVCNAAMLI\n",
       "17        MSVLNDQYA\n",
       "18         QQWNFAGI\n",
       "19        VNNTATLLM\n",
       "20        ASKQNLDSI\n",
       "21       QAYYWLLTAL\n",
       "22       AQREIFSAWI\n",
       "23        QLSPYPFDL\n",
       "24         INYLVPFL\n",
       "25        IGLCKTLGS\n",
       "26        RYHVVLTMA\n",
       "27       SAFIVYYYHI\n",
       "28        KQTCNSSAV\n",
       "29       NSSILFPDDV\n",
       "           ...     \n",
       "5854      LIIVQIILL\n",
       "5855       QTFRFMHL\n",
       "5856       FPPNYKLL\n",
       "5857      VILALYSAM\n",
       "5858     SGVNMFRNHL\n",
       "5859       SPGQLIQR\n",
       "5860     IRLINDSTDV\n",
       "5861     YAIAMLPVFL\n",
       "5862       SVIFLAIL\n",
       "5863      IPLTNITYW\n",
       "5864       EEGEGRVI\n",
       "5865      GYIREALVI\n",
       "5866       AIKPYNPL\n",
       "5867      KNIQSLRRL\n",
       "5868       LAILYILL\n",
       "5869       LLFNFLSL\n",
       "5870      TYWCYITEL\n",
       "5871      STPAHHHSL\n",
       "5872    PVFFYYILGLM\n",
       "5873      SPSYVYHQF\n",
       "5874      CALMDCIIF\n",
       "5875    VALIAIPWYAM\n",
       "5876      SYLNARIFL\n",
       "5877      KYLGFCVFA\n",
       "5878      LSYNIYPFL\n",
       "5879      SLLGNATAL\n",
       "5880      SMITMSAFL\n",
       "5881      SRVFIATHF\n",
       "5882     EVPFPVVNAM\n",
       "5883      YTFMLYAFI\n",
       "Name: Peptide, Length: 5884, dtype: object"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rtrain-AUC: %s - val-AUC: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides = np.load('peptides.npy')\n",
    "mhc = np.load('mhc.npy')\n",
    "affinity = np.log(1+np.load('affinity.npy'))/10\n",
    "labels = np.load('immu.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([147., 360., 479., 608., 690., 767., 853., 789., 652., 539.]),\n",
       " array([0.09633163, 0.19333493, 0.29033823, 0.38734153, 0.48434483,\n",
       "        0.58134813, 0.67835143, 0.77535473, 0.87235803, 0.96936133,\n",
       "        1.06636462]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(affinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5884, 11, 20), (5884, 11, 11))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptides_A = peptides[:, :, :20]\n",
    "peptides_B = peptides[:, :, 20:]\n",
    "peptides_A.shape, peptides_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_1_A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-d87962890125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_1_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'input_1_A' is not defined"
     ]
    }
   ],
   "source": [
    "input_1_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 11, 20, 12), (None, 11, 11)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-82aaacf2371d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'input_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'elu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36data/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \"\"\"\n\u001b[0;32m--> 649\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36data/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36data/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    360\u001b[0m                              \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                              \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                              'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 11, 20, 12), (None, 11, 11)]"
     ]
    }
   ],
   "source": [
    "input_1 = Input(shape=(11, 20,), name = 'input_1')\n",
    "x1 = Embedding(input_dim = 20, output_dim=12)(input_1)\n",
    "\n",
    "input_2 = Input(shape=(11, 11,), name = 'input_2')\n",
    "\n",
    "x2 = concatenate([x1, input_2], axis=-1)\n",
    "\n",
    "x2 = Conv1D(16, 3, padding='same', activation = 'elu')(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = AveragePooling(3)(x2)\n",
    "\n",
    "x2_a = Conv1D(16, 3, padding='same', activation = 'elu')(x2)\n",
    "x2_a = BatchNormalization()(x2_a)\n",
    "x3 = add([x2, x2_a])\n",
    "x3 = Conv1D(32, 3, padding='same', activation = 'elu')(x3)\n",
    "x3 = MaxPooling1D(x3)                 \n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "merged = concatenate([x3, input_3], axis=-1)\n",
    "x4 = Dense(32, activation = 'relu')(merged)\n",
    "x4 = Dropout(0.3)(x4)\n",
    "x4 = Dense(32, activation = 'relu')(x4)\n",
    "x4 = Dropout(0.3)(x4)\n",
    "predictions = Dense(2, activation='softmax')(x4)\n",
    "\n",
    "model = Model(inputs=[input_1, input_2, input_3], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0012), loss='categorical_crossentropy', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 11, 31)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 11, 31)       124         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 11, 16)       1504        batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 11, 16)       64          conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 11, 16)       784         batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 11, 16)       64          conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 11, 16)       784         batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 11, 16)       64          conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 11, 16)       0           batch_normalization_113[0][0]    \n",
      "                                                                 batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 11, 32)       1568        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 11, 32)       128         conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 352)          0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 352)          0           flatten_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 2)            706         dropout_30[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,790\n",
      "Trainable params: 5,568\n",
      "Non-trainable params: 222\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5295 samples, validate on 589 samples\n",
      "Epoch 1/30\n",
      "5295/5295 [==============================] - 13s 3ms/step - loss: 0.4482 - acc: 0.8100 - auc: 0.8701 - val_loss: 0.4874 - val_acc: 0.7827 - val_auc: 0.8704\n",
      "Epoch 2/30\n",
      "5295/5295 [==============================] - 4s 728us/step - loss: 0.4377 - acc: 0.8093 - auc: 0.8726 - val_loss: 0.4890 - val_acc: 0.7929 - val_auc: 0.8734\n",
      "Epoch 3/30\n",
      "5295/5295 [==============================] - 4s 719us/step - loss: 0.4461 - acc: 0.8091 - auc: 0.8740 - val_loss: 0.4890 - val_acc: 0.7776 - val_auc: 0.8732\n",
      "Epoch 4/30\n",
      "5295/5295 [==============================] - 4s 720us/step - loss: 0.4200 - acc: 0.8204 - auc: 0.8751 - val_loss: 0.4984 - val_acc: 0.7844 - val_auc: 0.8763\n",
      "Epoch 5/30\n",
      "5295/5295 [==============================] - 4s 753us/step - loss: 0.4226 - acc: 0.8225 - auc: 0.8776 - val_loss: 0.4943 - val_acc: 0.7657 - val_auc: 0.8779\n",
      "Epoch 6/30\n",
      "5295/5295 [==============================] - 4s 740us/step - loss: 0.4177 - acc: 0.8236 - auc: 0.8796 - val_loss: 0.5046 - val_acc: 0.7844 - val_auc: 0.8794\n",
      "Epoch 7/30\n",
      "5295/5295 [==============================] - 4s 766us/step - loss: 0.4069 - acc: 0.8261 - auc: 0.8806 - val_loss: 0.5102 - val_acc: 0.7844 - val_auc: 0.8812\n",
      "Epoch 8/30\n",
      "5295/5295 [==============================] - 4s 830us/step - loss: 0.3990 - acc: 0.8306 - auc: 0.8822 - val_loss: 0.5026 - val_acc: 0.7997 - val_auc: 0.8831\n",
      "Epoch 9/30\n",
      "5295/5295 [==============================] - 4s 824us/step - loss: 0.3917 - acc: 0.8374 - auc: 0.8845 - val_loss: 0.5348 - val_acc: 0.7334 - val_auc: 0.8849\n",
      "Epoch 10/30\n",
      "5295/5295 [==============================] - 4s 794us/step - loss: 0.3889 - acc: 0.8363 - auc: 0.8857 - val_loss: 0.5156 - val_acc: 0.7776 - val_auc: 0.8864\n",
      "Epoch 11/30\n",
      "5295/5295 [==============================] - 5s 866us/step - loss: 0.3812 - acc: 0.8368 - auc: 0.8874 - val_loss: 0.5320 - val_acc: 0.7963 - val_auc: 0.8880\n",
      "Epoch 12/30\n",
      "5295/5295 [==============================] - 5s 858us/step - loss: 0.3729 - acc: 0.8353 - auc: 0.8888 - val_loss: 0.5312 - val_acc: 0.7759 - val_auc: 0.8896\n",
      "Epoch 13/30\n",
      "5295/5295 [==============================] - 4s 785us/step - loss: 0.3726 - acc: 0.8436 - auc: 0.8904 - val_loss: 0.5413 - val_acc: 0.7708 - val_auc: 0.8911\n",
      "Epoch 14/30\n",
      "5295/5295 [==============================] - 4s 831us/step - loss: 0.3672 - acc: 0.8406 - auc: 0.8919 - val_loss: 0.5161 - val_acc: 0.7827 - val_auc: 0.8925\n",
      "Epoch 15/30\n",
      "5295/5295 [==============================] - 5s 885us/step - loss: 0.3560 - acc: 0.8504 - auc: 0.8934 - val_loss: 0.5343 - val_acc: 0.7861 - val_auc: 0.8941\n",
      "Epoch 16/30\n",
      "5295/5295 [==============================] - 5s 865us/step - loss: 0.3536 - acc: 0.8495 - auc: 0.8949 - val_loss: 0.5712 - val_acc: 0.7827 - val_auc: 0.8955\n",
      "Epoch 17/30\n",
      "5295/5295 [==============================] - 4s 835us/step - loss: 0.3424 - acc: 0.8536 - auc: 0.8965 - val_loss: 0.5661 - val_acc: 0.7708 - val_auc: 0.8970\n",
      "Epoch 18/30\n",
      "5295/5295 [==============================] - 4s 806us/step - loss: 0.3384 - acc: 0.8536 - auc: 0.8979 - val_loss: 0.5582 - val_acc: 0.7589 - val_auc: 0.8984\n",
      "Epoch 19/30\n",
      "5295/5295 [==============================] - 5s 876us/step - loss: 0.3336 - acc: 0.8589 - auc: 0.8991 - val_loss: 0.5712 - val_acc: 0.7640 - val_auc: 0.8997\n",
      "Epoch 20/30\n",
      "5295/5295 [==============================] - 5s 898us/step - loss: 0.3324 - acc: 0.8606 - auc: 0.9005 - val_loss: 0.5711 - val_acc: 0.7487 - val_auc: 0.9010\n",
      "Epoch 21/30\n",
      "5295/5295 [==============================] - 4s 847us/step - loss: 0.3343 - acc: 0.8572 - auc: 0.9015 - val_loss: 0.5933 - val_acc: 0.7912 - val_auc: 0.9020\n",
      "Epoch 22/30\n",
      "5295/5295 [==============================] - 5s 871us/step - loss: 0.3210 - acc: 0.8618 - auc: 0.9027 - val_loss: 0.5938 - val_acc: 0.7844 - val_auc: 0.9032\n",
      "Epoch 23/30\n",
      "5295/5295 [==============================] - 5s 857us/step - loss: 0.3172 - acc: 0.8648 - auc: 0.9039 - val_loss: 0.6046 - val_acc: 0.7640 - val_auc: 0.9044\n",
      "Epoch 24/30\n",
      "5295/5295 [==============================] - 4s 825us/step - loss: 0.3023 - acc: 0.8695 - auc: 0.9052 - val_loss: 0.6019 - val_acc: 0.7708 - val_auc: 0.9058\n",
      "Epoch 25/30\n",
      "5295/5295 [==============================] - 5s 870us/step - loss: 0.2991 - acc: 0.8746 - auc: 0.9065 - val_loss: 0.6321 - val_acc: 0.7521 - val_auc: 0.9070\n",
      "Epoch 26/30\n",
      "5295/5295 [==============================] - 5s 901us/step - loss: 0.3022 - acc: 0.8735 - auc: 0.9076 - val_loss: 0.6187 - val_acc: 0.7657 - val_auc: 0.9081\n",
      "Epoch 27/30\n",
      "5295/5295 [==============================] - 5s 852us/step - loss: 0.2917 - acc: 0.8738 - auc: 0.9088 - val_loss: 0.6313 - val_acc: 0.7623 - val_auc: 0.9093\n",
      "Epoch 28/30\n",
      "5295/5295 [==============================] - 5s 884us/step - loss: 0.2890 - acc: 0.8765 - auc: 0.9099 - val_loss: 0.6631 - val_acc: 0.7742 - val_auc: 0.9104\n",
      "Epoch 29/30\n",
      "5295/5295 [==============================] - 4s 845us/step - loss: 0.2778 - acc: 0.8810 - auc: 0.9110 - val_loss: 0.6681 - val_acc: 0.7844 - val_auc: 0.9115\n",
      "Epoch 30/30\n",
      "5295/5295 [==============================] - 5s 887us/step - loss: 0.2803 - acc: 0.8835 - auc: 0.9121 - val_loss: 0.6877 - val_acc: 0.7742 - val_auc: 0.9126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab69edbf60>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([peptides, affinity], to_categorical(labels), batch_size=32, validation_split=0.1, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(11, 31,), name = 'input_1')\n",
    "#input_2 = Input(shape=(6,), name = 'input_2')\n",
    "input_3 = Input(shape=(1,), name = 'input_3')\n",
    "\n",
    "x1 = Conv1D(16, 3, padding='same', activation = 'elu')(input_1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "\n",
    "x1_a = Conv1D(16, 3, padding='same', activation = 'elu')(x1)\n",
    "x1_a = BatchNormalization()(x1_a)\n",
    "\n",
    "x2 = add([x1, x1_a])\n",
    "x2 = Conv1D(32, 3, padding='same', activation = 'elu')(x1)\n",
    "x2 = BatchNormalization()(x2)\n",
    "#x2 = MaxPooling1D()(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "merged = concatenate([x2, input_3], axis=-1)\n",
    "x4 = Dense(32, activation = 'relu')(merged)\n",
    "x4 = Dropout(0.3)(x4)\n",
    "x4 = Dense(32, activation = 'relu')(x4)\n",
    "x4 = Dropout(0.3)(x4)\n",
    "predictions = Dense(2, activation='softmax')(x4)\n",
    "\n",
    "model_2 = Model(inputs=[input_1, input_3], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy', auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5295 samples, validate on 589 samples\n",
      "Epoch 1/10\n",
      "5295/5295 [==============================] - 27s 5ms/step - loss: 0.6065 - acc: 0.7330 - auc: 0.7249 - val_loss: 0.5103 - val_acc: 0.7861 - val_auc: 0.7764\n",
      "Epoch 2/10\n",
      "5295/5295 [==============================] - 2s 347us/step - loss: 0.5344 - acc: 0.7815 - auc: 0.7865 - val_loss: 0.5017 - val_acc: 0.7861 - val_auc: 0.7954\n",
      "Epoch 3/10\n",
      "5295/5295 [==============================] - 2s 357us/step - loss: 0.5229 - acc: 0.7862 - auc: 0.8000 - val_loss: 0.5133 - val_acc: 0.7861 - val_auc: 0.8034\n",
      "Epoch 4/10\n",
      "5295/5295 [==============================] - 2s 361us/step - loss: 0.5088 - acc: 0.7881 - auc: 0.8068 - val_loss: 0.5021 - val_acc: 0.7861 - val_auc: 0.8094\n",
      "Epoch 5/10\n",
      "5295/5295 [==============================] - 2s 392us/step - loss: 0.5087 - acc: 0.7883 - auc: 0.8115 - val_loss: 0.5030 - val_acc: 0.7861 - val_auc: 0.8132\n",
      "Epoch 6/10\n",
      "5295/5295 [==============================] - 2s 347us/step - loss: 0.5015 - acc: 0.7890 - auc: 0.8147 - val_loss: 0.5003 - val_acc: 0.7861 - val_auc: 0.8161\n",
      "Epoch 7/10\n",
      "5295/5295 [==============================] - 2s 350us/step - loss: 0.4984 - acc: 0.7885 - auc: 0.8174 - val_loss: 0.4959 - val_acc: 0.7861 - val_auc: 0.8186\n",
      "Epoch 8/10\n",
      "5295/5295 [==============================] - 2s 357us/step - loss: 0.4954 - acc: 0.7887 - auc: 0.8198 - val_loss: 0.5003 - val_acc: 0.7861 - val_auc: 0.8209\n",
      "Epoch 9/10\n",
      "5295/5295 [==============================] - 2s 354us/step - loss: 0.4964 - acc: 0.7896 - auc: 0.8217 - val_loss: 0.5029 - val_acc: 0.7861 - val_auc: 0.8224\n",
      "Epoch 10/10\n",
      "5295/5295 [==============================] - 2s 370us/step - loss: 0.4931 - acc: 0.7889 - auc: 0.8233 - val_loss: 0.5086 - val_acc: 0.7878 - val_auc: 0.8238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab40f284a8>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit([peptides, affinity], to_categorical(labels), batch_size=64, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_1 = Input(shape=(11, 31,), name = 'input_1')\n",
    "    input_3 = Input(shape=(1,), name = 'input_3')\n",
    "\n",
    "    x1 = Conv1D(16, 3, padding='same', activation = 'elu')(input_1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "\n",
    "    x1_a = Conv1D(16, 3, padding='same', activation = 'elu')(x1)\n",
    "    x1_a = BatchNormalization()(x1_a)\n",
    "\n",
    "    x2 = add([x1, x1_a])\n",
    "    x2 = Conv1D(32, 3, padding='same', activation = 'elu')(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    #x2 = MaxPooling1D()(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "\n",
    "    merged = concatenate([x2, input_3], axis=-1)\n",
    "    x4 = Dense(32, activation = 'relu')(merged)\n",
    "    x4 = Dropout(0.3)(x4)\n",
    "    x4 = Dense(32, activation = 'relu')(x4)\n",
    "    x4 = Dropout(0.3)(x4)\n",
    "    predictions = Dense(2, activation='softmax')(x4)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_3], outputs=predictions)\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy', auc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        print(y_pred)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rtrain-AUC: %s - val-AUC: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "Epoch 1/20\n",
      "4706/4706 [==============================] - 24s 5ms/step - loss: 0.5762 - acc: 0.7465 - auc: 0.7791\n",
      "[[0.9920427  0.0079573 ]\n",
      " [0.70975363 0.29024637]\n",
      " [0.6853417  0.31465828]\n",
      " ...\n",
      " [0.7291592  0.27084085]\n",
      " [0.81007594 0.189924  ]\n",
      " [0.7186179  0.28138208]]\n",
      "train-AUC: 0.6233 - val-AUC: 0.6043                                                                                                    \n",
      "Epoch 2/20\n",
      "4706/4706 [==============================] - 1s 204us/step - loss: 0.5278 - acc: 0.7835 - auc: 0.8046\n",
      "[[0.96889204 0.03110795]\n",
      " [0.66694975 0.33305022]\n",
      " [0.6354434  0.36455652]\n",
      " ...\n",
      " [0.63697904 0.3630209 ]\n",
      " [0.7827812  0.2172188 ]\n",
      " [0.7330462  0.26695386]]\n",
      "train-AUC: 0.6418 - val-AUC: 0.6261                                                                                                    \n",
      "Epoch 3/20\n",
      "4706/4706 [==============================] - 1s 199us/step - loss: 0.5219 - acc: 0.7847 - auc: 0.8078\n",
      "[[0.9668031  0.03319697]\n",
      " [0.686406   0.31359398]\n",
      " [0.7457633  0.25423676]\n",
      " ...\n",
      " [0.74520195 0.25479802]\n",
      " [0.6777473  0.3222527 ]\n",
      " [0.7758985  0.2241015 ]]\n",
      "train-AUC: 0.652 - val-AUC: 0.6136                                                                                                    \n",
      "Epoch 4/20\n",
      "4706/4706 [==============================] - 1s 206us/step - loss: 0.5072 - acc: 0.7881 - auc: 0.8124\n",
      "[[0.9669808  0.03301914]\n",
      " [0.69367945 0.30632052]\n",
      " [0.6470151  0.35298488]\n",
      " ...\n",
      " [0.73660976 0.2633902 ]\n",
      " [0.76976067 0.23023927]\n",
      " [0.7398459  0.26015407]]\n",
      "train-AUC: 0.6667 - val-AUC: 0.6319                                                                                                    \n",
      "Epoch 5/20\n",
      "4706/4706 [==============================] - 1s 248us/step - loss: 0.5124 - acc: 0.7886 - auc: 0.8162\n",
      "[[0.9060529  0.09394715]\n",
      " [0.7138165  0.2861835 ]\n",
      " [0.7199367  0.2800632 ]\n",
      " ...\n",
      " [0.7576482  0.24235176]\n",
      " [0.74483633 0.2551637 ]\n",
      " [0.7492119  0.2507881 ]]\n",
      "train-AUC: 0.6803 - val-AUC: 0.6255                                                                                                    \n",
      "Epoch 6/20\n",
      "4706/4706 [==============================] - 1s 234us/step - loss: 0.5015 - acc: 0.7888 - auc: 0.8187\n",
      "[[0.9363357  0.06366433]\n",
      " [0.73404294 0.26595706]\n",
      " [0.7532178  0.24678212]\n",
      " ...\n",
      " [0.7636752  0.2363248 ]\n",
      " [0.7414326  0.25856736]\n",
      " [0.80056214 0.19943783]]\n",
      "train-AUC: 0.6936 - val-AUC: 0.6176                                                                                                    \n",
      "Epoch 7/20\n",
      "4706/4706 [==============================] - 1s 231us/step - loss: 0.5054 - acc: 0.7890 - auc: 0.8197\n",
      "[[0.94443035 0.0555696 ]\n",
      " [0.745771   0.25422898]\n",
      " [0.70804363 0.2919564 ]\n",
      " ...\n",
      " [0.81037295 0.18962707]\n",
      " [0.78257716 0.21742283]\n",
      " [0.852725   0.14727502]]\n",
      "train-AUC: 0.6889 - val-AUC: 0.6116                                                                                                    \n",
      "Epoch 8/20\n",
      "4706/4706 [==============================] - 1s 226us/step - loss: 0.5011 - acc: 0.7888 - auc: 0.8216\n",
      "[[0.85147715 0.14852288]\n",
      " [0.72760314 0.27239686]\n",
      " [0.6973269  0.30267313]\n",
      " ...\n",
      " [0.80937856 0.19062148]\n",
      " [0.7461651  0.2538349 ]\n",
      " [0.75811106 0.24188893]]\n",
      "train-AUC: 0.6982 - val-AUC: 0.6153                                                                                                    \n",
      "Epoch 9/20\n",
      "4706/4706 [==============================] - 1s 260us/step - loss: 0.4948 - acc: 0.7886 - auc: 0.8228\n",
      "[[0.89503735 0.10496264]\n",
      " [0.6974545  0.30254552]\n",
      " [0.7005461  0.2994539 ]\n",
      " ...\n",
      " [0.82594824 0.17405179]\n",
      " [0.77757436 0.22242565]\n",
      " [0.77122366 0.22877635]]\n",
      "train-AUC: 0.698 - val-AUC: 0.6295                                                                                                    \n",
      "Epoch 10/20\n",
      "4706/4706 [==============================] - 1s 224us/step - loss: 0.4924 - acc: 0.7890 - auc: 0.8244\n",
      "[[0.88854295 0.11145701]\n",
      " [0.73051655 0.2694834 ]\n",
      " [0.7499697  0.25003025]\n",
      " ...\n",
      " [0.7702921  0.22970793]\n",
      " [0.7907422  0.20925781]\n",
      " [0.7936948  0.20630524]]\n",
      "train-AUC: 0.6984 - val-AUC: 0.6327                                                                                                    \n",
      "Epoch 11/20\n",
      "4706/4706 [==============================] - 1s 260us/step - loss: 0.4941 - acc: 0.7890 - auc: 0.8258\n",
      "[[0.89275306 0.10724695]\n",
      " [0.67680055 0.3231994 ]\n",
      " [0.6494968  0.3505032 ]\n",
      " ...\n",
      " [0.71657217 0.28342777]\n",
      " [0.8028514  0.19714862]\n",
      " [0.70447147 0.2955286 ]]\n",
      "train-AUC: 0.7066 - val-AUC: 0.6372                                                                                                    \n",
      "Epoch 12/20\n",
      "4706/4706 [==============================] - 1s 239us/step - loss: 0.4898 - acc: 0.7888 - auc: 0.8266\n",
      "[[0.9207192  0.07928082]\n",
      " [0.6941635  0.30583644]\n",
      " [0.6859999  0.3140001 ]\n",
      " ...\n",
      " [0.7959415  0.20405848]\n",
      " [0.7156461  0.2843539 ]\n",
      " [0.7455176  0.25448242]]\n",
      "train-AUC: 0.712 - val-AUC: 0.6409                                                                                                    \n",
      "Epoch 13/20\n",
      "4706/4706 [==============================] - 1s 215us/step - loss: 0.4863 - acc: 0.7892 - auc: 0.8278\n",
      "[[0.93820834 0.0617917 ]\n",
      " [0.66603464 0.3339654 ]\n",
      " [0.72681636 0.2731836 ]\n",
      " ...\n",
      " [0.87280124 0.12719877]\n",
      " [0.76037705 0.23962294]\n",
      " [0.7582598  0.24174024]]\n",
      "train-AUC: 0.7122 - val-AUC: 0.6253                                                                                                    \n",
      "Epoch 14/20\n",
      "4706/4706 [==============================] - 1s 217us/step - loss: 0.4837 - acc: 0.7892 - auc: 0.8288\n",
      "[[0.9446264  0.05537367]\n",
      " [0.6950451  0.30495483]\n",
      " [0.7255109  0.27448907]\n",
      " ...\n",
      " [0.857441   0.14255892]\n",
      " [0.7290502  0.27094972]\n",
      " [0.7560331  0.24396683]]\n",
      "train-AUC: 0.7232 - val-AUC: 0.6242                                                                                                    \n",
      "Epoch 15/20\n",
      "4706/4706 [==============================] - 1s 215us/step - loss: 0.4832 - acc: 0.7888 - auc: 0.8301\n",
      "[[0.96289515 0.0371048 ]\n",
      " [0.7011321  0.2988679 ]\n",
      " [0.6631346  0.33686543]\n",
      " ...\n",
      " [0.8817822  0.11821781]\n",
      " [0.74674755 0.25325242]\n",
      " [0.7623199  0.23768003]]\n",
      "train-AUC: 0.7243 - val-AUC: 0.6433                                                                                                    \n",
      "Epoch 16/20\n",
      "4706/4706 [==============================] - 1s 238us/step - loss: 0.4846 - acc: 0.7901 - auc: 0.8312\n",
      "[[0.96130115 0.03869889]\n",
      " [0.6752993  0.32470077]\n",
      " [0.69332665 0.30667332]\n",
      " ...\n",
      " [0.78528047 0.2147195 ]\n",
      " [0.8148312  0.18516886]\n",
      " [0.73673505 0.26326498]]\n",
      "train-AUC: 0.7303 - val-AUC: 0.6296                                                                                                    \n",
      "Epoch 17/20\n",
      "4706/4706 [==============================] - 1s 217us/step - loss: 0.4839 - acc: 0.7888 - auc: 0.8318\n",
      "[[0.94154334 0.05845661]\n",
      " [0.67764103 0.32235897]\n",
      " [0.7250386  0.27496138]\n",
      " ...\n",
      " [0.7975438  0.20245618]\n",
      " [0.791035   0.20896497]\n",
      " [0.7373062  0.26269385]]\n",
      "train-AUC: 0.7328 - val-AUC: 0.6332                                                                                                    \n",
      "Epoch 18/20\n",
      "4706/4706 [==============================] - 1s 216us/step - loss: 0.4766 - acc: 0.7894 - auc: 0.8328\n",
      "[[0.9524923  0.04750778]\n",
      " [0.73149455 0.26850554]\n",
      " [0.6561104  0.34388956]\n",
      " ...\n",
      " [0.849125   0.150875  ]\n",
      " [0.83571076 0.16428922]\n",
      " [0.70213866 0.2978613 ]]\n",
      "train-AUC: 0.7349 - val-AUC: 0.6388                                                                                                    \n",
      "Epoch 19/20\n",
      "4706/4706 [==============================] - 1s 217us/step - loss: 0.4837 - acc: 0.7886 - auc: 0.8335\n",
      "[[0.9515537  0.04844632]\n",
      " [0.7466116  0.2533884 ]\n",
      " [0.69506323 0.30493674]\n",
      " ...\n",
      " [0.80844384 0.19155614]\n",
      " [0.776373   0.22362703]\n",
      " [0.7871247  0.21287538]]\n",
      "train-AUC: 0.744 - val-AUC: 0.6387                                                                                                    \n",
      "Epoch 20/20\n",
      "4706/4706 [==============================] - 1s 224us/step - loss: 0.4742 - acc: 0.7909 - auc: 0.8344\n",
      "[[0.9569984  0.0430016 ]\n",
      " [0.7080844  0.2919156 ]\n",
      " [0.65824133 0.34175864]\n",
      " ...\n",
      " [0.8045546  0.19544539]\n",
      " [0.8005445  0.19945547]\n",
      " [0.74415594 0.2558441 ]]\n",
      "train-AUC: 0.7442 - val-AUC: 0.6313                                                                                                    \n",
      "\n",
      "Fold  1\n",
      "Epoch 1/20\n",
      "4707/4707 [==============================] - 27s 6ms/step - loss: 0.5730 - acc: 0.7519 - auc: 0.7807\n",
      "[[0.86672324 0.13327669]\n",
      " [0.7045393  0.29546064]\n",
      " [0.8108003  0.1891997 ]\n",
      " ...\n",
      " [0.7017141  0.2982859 ]\n",
      " [0.6042713  0.3957287 ]\n",
      " [0.97431403 0.02568594]]\n",
      "train-AUC: 0.6439 - val-AUC: 0.6255                                                                                                    \n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 1s 236us/step - loss: 0.5309 - acc: 0.7827 - auc: 0.7996\n",
      "[[0.8621299  0.13787009]\n",
      " [0.7227945  0.2772056 ]\n",
      " [0.82326776 0.17673226]\n",
      " ...\n",
      " [0.6874737  0.31252623]\n",
      " [0.6168614  0.38313863]\n",
      " [0.8991254  0.10087463]]\n",
      "train-AUC: 0.6671 - val-AUC: 0.6529                                                                                                    \n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 1s 294us/step - loss: 0.5147 - acc: 0.7867 - auc: 0.8082\n",
      "[[0.91414934 0.08585071]\n",
      " [0.7810174  0.21898265]\n",
      " [0.84124446 0.15875557]\n",
      " ...\n",
      " [0.6482355  0.35176456]\n",
      " [0.6951948  0.30480522]\n",
      " [0.90383273 0.09616724]]\n",
      "train-AUC: 0.6724 - val-AUC: 0.6491                                                                                                    \n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 1s 209us/step - loss: 0.5083 - acc: 0.7880 - auc: 0.8128\n",
      "[[0.92573994 0.07426005]\n",
      " [0.75077343 0.2492265 ]\n",
      " [0.83474606 0.16525388]\n",
      " ...\n",
      " [0.62219983 0.37780017]\n",
      " [0.6675277  0.33247232]\n",
      " [0.90366673 0.09633326]]\n",
      "train-AUC: 0.6831 - val-AUC: 0.6505                                                                                                    \n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 1s 251us/step - loss: 0.4982 - acc: 0.7882 - auc: 0.8173\n",
      "[[0.9325214  0.06747867]\n",
      " [0.76178    0.23822   ]\n",
      " [0.8812898  0.11871024]\n",
      " ...\n",
      " [0.5870984  0.41290152]\n",
      " [0.618774   0.38122603]\n",
      " [0.89844936 0.10155061]]\n",
      "train-AUC: 0.6929 - val-AUC: 0.6459                                                                                                    \n",
      "Epoch 6/20\n",
      "4707/4707 [==============================] - 1s 253us/step - loss: 0.4996 - acc: 0.7884 - auc: 0.8198\n",
      "[[0.9406842  0.05931576]\n",
      " [0.82033604 0.17966393]\n",
      " [0.851275   0.14872496]\n",
      " ...\n",
      " [0.6700774  0.32992265]\n",
      " [0.7106204  0.28937957]\n",
      " [0.87798834 0.12201163]]\n",
      "train-AUC: 0.6884 - val-AUC: 0.6301                                                                                                    \n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 1s 268us/step - loss: 0.4968 - acc: 0.7882 - auc: 0.8219\n",
      "[[0.9714812  0.02851883]\n",
      " [0.7551456  0.24485439]\n",
      " [0.8466615  0.15333848]\n",
      " ...\n",
      " [0.6341087  0.36589128]\n",
      " [0.6953212  0.30467883]\n",
      " [0.8621315  0.13786857]]\n",
      "train-AUC: 0.6967 - val-AUC: 0.6296                                                                                                    \n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 1s 246us/step - loss: 0.4986 - acc: 0.7888 - auc: 0.8246\n",
      "[[0.93915725 0.06084279]\n",
      " [0.7291133  0.2708867 ]\n",
      " [0.85629565 0.1437043 ]\n",
      " ...\n",
      " [0.61235934 0.3876406 ]\n",
      " [0.66652715 0.33347282]\n",
      " [0.8924205  0.10757948]]\n",
      "train-AUC: 0.7003 - val-AUC: 0.6297                                                                                                    \n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 1s 227us/step - loss: 0.4931 - acc: 0.7888 - auc: 0.8257\n",
      "[[0.9204077  0.07959229]\n",
      " [0.8292601  0.17073992]\n",
      " [0.8674204  0.13257968]\n",
      " ...\n",
      " [0.6816152  0.3183848 ]\n",
      " [0.755598   0.24440202]\n",
      " [0.9014842  0.09851584]]\n",
      "train-AUC: 0.6963 - val-AUC: 0.6334                                                                                                    \n",
      "Epoch 10/20\n",
      "4707/4707 [==============================] - 1s 220us/step - loss: 0.4959 - acc: 0.7886 - auc: 0.8270\n",
      "[[0.9390119  0.06098812]\n",
      " [0.8154115  0.18458846]\n",
      " [0.87562066 0.12437931]\n",
      " ...\n",
      " [0.644243   0.35575703]\n",
      " [0.73376805 0.26623192]\n",
      " [0.91959214 0.08040782]]\n",
      "train-AUC: 0.7078 - val-AUC: 0.6312                                                                                                    \n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 1s 221us/step - loss: 0.4891 - acc: 0.7888 - auc: 0.8285\n",
      "[[0.93294066 0.06705933]\n",
      " [0.70651263 0.2934874 ]\n",
      " [0.8961101  0.10388988]\n",
      " ...\n",
      " [0.660304   0.33969596]\n",
      " [0.7297687  0.2702313 ]\n",
      " [0.9292239  0.07077608]]\n",
      "train-AUC: 0.7194 - val-AUC: 0.6435                                                                                                    \n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 1s 266us/step - loss: 0.4872 - acc: 0.7888 - auc: 0.8295\n",
      "[[0.9607328  0.03926714]\n",
      " [0.7644278  0.2355722 ]\n",
      " [0.9033668  0.09663326]\n",
      " ...\n",
      " [0.62238795 0.37761208]\n",
      " [0.7736477  0.22635229]\n",
      " [0.9432659  0.0567341 ]]\n",
      "train-AUC: 0.7249 - val-AUC: 0.628                                                                                                    \n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 1s 228us/step - loss: 0.4831 - acc: 0.7890 - auc: 0.8310\n",
      "[[0.9351223  0.06487772]\n",
      " [0.755624   0.24437606]\n",
      " [0.91335815 0.08664189]\n",
      " ...\n",
      " [0.62347186 0.3765281 ]\n",
      " [0.7509576  0.24904238]\n",
      " [0.9331175  0.06688249]]\n",
      "train-AUC: 0.729 - val-AUC: 0.6407                                                                                                    \n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 1s 260us/step - loss: 0.4804 - acc: 0.7886 - auc: 0.8320\n",
      "[[0.9558997  0.04410025]\n",
      " [0.7744863  0.22551368]\n",
      " [0.88677186 0.11322812]\n",
      " ...\n",
      " [0.614811   0.38518897]\n",
      " [0.7529313  0.24706873]\n",
      " [0.9158349  0.08416509]]\n",
      "train-AUC: 0.7303 - val-AUC: 0.6325                                                                                                    \n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 1s 306us/step - loss: 0.4822 - acc: 0.7893 - auc: 0.8333\n",
      "[[0.94999826 0.05000176]\n",
      " [0.69218487 0.30781513]\n",
      " [0.8964324  0.1035676 ]\n",
      " ...\n",
      " [0.5972484  0.4027516 ]\n",
      " [0.7162381  0.28376195]\n",
      " [0.9478996  0.05210038]]\n",
      "train-AUC: 0.7348 - val-AUC: 0.6306                                                                                                    \n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 1s 259us/step - loss: 0.4766 - acc: 0.7893 - auc: 0.8344\n",
      "[[0.96560884 0.03439117]\n",
      " [0.7357735  0.26422656]\n",
      " [0.91838175 0.08161828]\n",
      " ...\n",
      " [0.60243225 0.39756775]\n",
      " [0.7547365  0.2452635 ]\n",
      " [0.9479439  0.05205608]]\n",
      "train-AUC: 0.7406 - val-AUC: 0.6405                                                                                                    \n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 1s 234us/step - loss: 0.4759 - acc: 0.7890 - auc: 0.8355\n",
      "[[0.94172454 0.0582755 ]\n",
      " [0.71607    0.28393006]\n",
      " [0.8885284  0.11147162]\n",
      " ...\n",
      " [0.6012521  0.39874792]\n",
      " [0.796689   0.20331106]\n",
      " [0.95593745 0.04406257]]\n",
      "train-AUC: 0.7505 - val-AUC: 0.6294                                                                                                    \n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 1s 230us/step - loss: 0.4709 - acc: 0.7886 - auc: 0.8364\n",
      "[[0.97729367 0.02270633]\n",
      " [0.65612274 0.3438773 ]\n",
      " [0.91749084 0.08250909]\n",
      " ...\n",
      " [0.61973274 0.3802673 ]\n",
      " [0.69948035 0.3005196 ]\n",
      " [0.9657724  0.03422769]]\n",
      "train-AUC: 0.7506 - val-AUC: 0.6293                                                                                                    \n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 1s 234us/step - loss: 0.4786 - acc: 0.7897 - auc: 0.8375\n",
      "[[0.9490604  0.05093957]\n",
      " [0.6522533  0.3477467 ]\n",
      " [0.9332752  0.06672479]\n",
      " ...\n",
      " [0.6587652  0.3412348 ]\n",
      " [0.72491467 0.27508536]\n",
      " [0.957746   0.04225396]]\n",
      "train-AUC: 0.7559 - val-AUC: 0.6229                                                                                                    \n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 1s 254us/step - loss: 0.4683 - acc: 0.7893 - auc: 0.8384\n",
      "[[0.9278259  0.072174  ]\n",
      " [0.6536845  0.3463154 ]\n",
      " [0.9260222  0.07397784]\n",
      " ...\n",
      " [0.60711163 0.3928884 ]\n",
      " [0.7449173  0.25508276]\n",
      " [0.96896243 0.03103754]]\n",
      "train-AUC: 0.761 - val-AUC: 0.633                                                                                                    \n",
      "\n",
      "Fold  2\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4707/4707 [==============================] - 25s 5ms/step - loss: 0.6010 - acc: 0.7436 - auc: 0.7759\n",
      "[[0.76151675 0.23848331]\n",
      " [0.94739974 0.05260026]\n",
      " [0.65843004 0.34156993]\n",
      " ...\n",
      " [0.72063833 0.2793616 ]\n",
      " [0.96162534 0.0383747 ]\n",
      " [0.8314803  0.16851969]]\n",
      "train-AUC: 0.6167 - val-AUC: 0.5777                                                                                                    \n",
      "Epoch 2/20\n",
      "4707/4707 [==============================] - 1s 221us/step - loss: 0.5406 - acc: 0.7780 - auc: 0.7923\n",
      "[[0.7520855  0.2479145 ]\n",
      " [0.8756055  0.12439449]\n",
      " [0.6796049  0.32039514]\n",
      " ...\n",
      " [0.82563096 0.174369  ]\n",
      " [0.88340753 0.11659244]\n",
      " [0.84029263 0.15970737]]\n",
      "train-AUC: 0.6547 - val-AUC: 0.5661                                                                                                    \n",
      "Epoch 3/20\n",
      "4707/4707 [==============================] - 1s 232us/step - loss: 0.5178 - acc: 0.7867 - auc: 0.8000\n",
      "[[0.7999839  0.2000161 ]\n",
      " [0.90648085 0.09351923]\n",
      " [0.7260488  0.27395114]\n",
      " ...\n",
      " [0.7676446  0.23235543]\n",
      " [0.93591595 0.06408406]\n",
      " [0.86567444 0.1343255 ]]\n",
      "train-AUC: 0.6801 - val-AUC: 0.6054                                                                                                    \n",
      "Epoch 4/20\n",
      "4707/4707 [==============================] - 1s 257us/step - loss: 0.5034 - acc: 0.7861 - auc: 0.8088\n",
      "[[0.88405365 0.11594635]\n",
      " [0.9057036  0.09429641]\n",
      " [0.6814012  0.3185988 ]\n",
      " ...\n",
      " [0.769559   0.23044097]\n",
      " [0.90935576 0.09064417]\n",
      " [0.8355016  0.16449839]]\n",
      "train-AUC: 0.6884 - val-AUC: 0.5994                                                                                                    \n",
      "Epoch 5/20\n",
      "4707/4707 [==============================] - 1s 286us/step - loss: 0.5052 - acc: 0.7869 - auc: 0.8129\n",
      "[[0.8783443  0.12165572]\n",
      " [0.92214406 0.07785593]\n",
      " [0.73803234 0.26196766]\n",
      " ...\n",
      " [0.7483389  0.2516611 ]\n",
      " [0.88749427 0.11250575]\n",
      " [0.82770175 0.17229824]]\n",
      "train-AUC: 0.6973 - val-AUC: 0.6034                                                                                                    \n",
      "Epoch 6/20\n",
      "4707/4707 [==============================] - 1s 234us/step - loss: 0.5016 - acc: 0.7888 - auc: 0.8170\n",
      "[[0.90364695 0.09635305]\n",
      " [0.9090377  0.09096226]\n",
      " [0.6866834  0.31331655]\n",
      " ...\n",
      " [0.77339196 0.22660807]\n",
      " [0.9279342  0.07206576]\n",
      " [0.8031366  0.19686343]]\n",
      "train-AUC: 0.7011 - val-AUC: 0.6127                                                                                                    \n",
      "Epoch 7/20\n",
      "4707/4707 [==============================] - 1s 236us/step - loss: 0.4927 - acc: 0.7914 - auc: 0.8195\n",
      "[[0.91066146 0.08933858]\n",
      " [0.90659326 0.09340665]\n",
      " [0.7301957  0.26980427]\n",
      " ...\n",
      " [0.754598   0.24540202]\n",
      " [0.8916196  0.10838041]\n",
      " [0.8366431  0.16335686]]\n",
      "train-AUC: 0.7121 - val-AUC: 0.616                                                                                                    \n",
      "Epoch 8/20\n",
      "4707/4707 [==============================] - 1s 265us/step - loss: 0.4922 - acc: 0.7886 - auc: 0.8224\n",
      "[[0.93153185 0.06846818]\n",
      " [0.9061764  0.09382365]\n",
      " [0.71854967 0.28145036]\n",
      " ...\n",
      " [0.7615415  0.23845853]\n",
      " [0.90294266 0.09705736]\n",
      " [0.80669534 0.19330463]]\n",
      "train-AUC: 0.7123 - val-AUC: 0.634                                                                                                    \n",
      "Epoch 9/20\n",
      "4707/4707 [==============================] - 1s 217us/step - loss: 0.4827 - acc: 0.7912 - auc: 0.8240\n",
      "[[0.9412734  0.05872653]\n",
      " [0.9304691  0.06953087]\n",
      " [0.7492729  0.25072715]\n",
      " ...\n",
      " [0.84048784 0.15951222]\n",
      " [0.89864725 0.10135272]\n",
      " [0.8832702  0.11672974]]\n",
      "train-AUC: 0.7236 - val-AUC: 0.6206                                                                                                    \n",
      "Epoch 10/20\n",
      "4707/4707 [==============================] - 1s 239us/step - loss: 0.4883 - acc: 0.7922 - auc: 0.8268\n",
      "[[0.942047   0.057953  ]\n",
      " [0.916356   0.08364398]\n",
      " [0.71785784 0.28214222]\n",
      " ...\n",
      " [0.73440737 0.2655926 ]\n",
      " [0.9216337  0.07836629]\n",
      " [0.7814816  0.21851842]]\n",
      "train-AUC: 0.7173 - val-AUC: 0.6197                                                                                                    \n",
      "Epoch 11/20\n",
      "4707/4707 [==============================] - 1s 231us/step - loss: 0.4844 - acc: 0.7914 - auc: 0.8284\n",
      "[[0.9096752  0.09032478]\n",
      " [0.9254654  0.07453462]\n",
      " [0.62805295 0.37194705]\n",
      " ...\n",
      " [0.7905227  0.2094773 ]\n",
      " [0.87839377 0.12160622]\n",
      " [0.77954733 0.2204527 ]]\n",
      "train-AUC: 0.7285 - val-AUC: 0.6182                                                                                                    \n",
      "Epoch 12/20\n",
      "4707/4707 [==============================] - 1s 218us/step - loss: 0.4822 - acc: 0.7912 - auc: 0.8300\n",
      "[[0.94472635 0.05527359]\n",
      " [0.9315123  0.06848777]\n",
      " [0.77037895 0.22962104]\n",
      " ...\n",
      " [0.766976   0.23302399]\n",
      " [0.9081396  0.09186039]\n",
      " [0.80117095 0.19882908]]\n",
      "train-AUC: 0.7324 - val-AUC: 0.6188                                                                                                    \n",
      "Epoch 13/20\n",
      "4707/4707 [==============================] - 1s 221us/step - loss: 0.4795 - acc: 0.7933 - auc: 0.8313\n",
      "[[0.94710463 0.05289535]\n",
      " [0.9186346  0.08136544]\n",
      " [0.69458157 0.30541843]\n",
      " ...\n",
      " [0.7350236  0.26497638]\n",
      " [0.9285501  0.07144985]\n",
      " [0.88010895 0.11989105]]\n",
      "train-AUC: 0.7283 - val-AUC: 0.6106                                                                                                    \n",
      "Epoch 14/20\n",
      "4707/4707 [==============================] - 1s 222us/step - loss: 0.4792 - acc: 0.7918 - auc: 0.8328\n",
      "[[0.9097851  0.09021493]\n",
      " [0.9243434  0.07565655]\n",
      " [0.6911532  0.30884686]\n",
      " ...\n",
      " [0.74563354 0.25436646]\n",
      " [0.8736988  0.12630126]\n",
      " [0.80852675 0.19147325]]\n",
      "train-AUC: 0.7395 - val-AUC: 0.607                                                                                                    \n",
      "Epoch 15/20\n",
      "4707/4707 [==============================] - 1s 222us/step - loss: 0.4815 - acc: 0.7914 - auc: 0.8338\n",
      "[[0.93707865 0.06292139]\n",
      " [0.8989052  0.10109473]\n",
      " [0.6465599  0.35344014]\n",
      " ...\n",
      " [0.71544814 0.28455186]\n",
      " [0.9166388  0.0833612 ]\n",
      " [0.81351787 0.18648218]]\n",
      "train-AUC: 0.7441 - val-AUC: 0.6164                                                                                                    \n",
      "Epoch 16/20\n",
      "4707/4707 [==============================] - 1s 219us/step - loss: 0.4742 - acc: 0.7920 - auc: 0.8351\n",
      "[[0.928595   0.071405  ]\n",
      " [0.9473128  0.05268722]\n",
      " [0.68102413 0.3189759 ]\n",
      " ...\n",
      " [0.7422009  0.2577991 ]\n",
      " [0.93399346 0.06600659]\n",
      " [0.7809159  0.21908413]]\n",
      "train-AUC: 0.7492 - val-AUC: 0.6158                                                                                                    \n",
      "Epoch 17/20\n",
      "4707/4707 [==============================] - 1s 222us/step - loss: 0.4703 - acc: 0.7946 - auc: 0.8361\n",
      "[[0.97329867 0.02670139]\n",
      " [0.92625725 0.07374275]\n",
      " [0.7180261  0.28197384]\n",
      " ...\n",
      " [0.7488613  0.25113875]\n",
      " [0.9337146  0.06628542]\n",
      " [0.8112005  0.18879956]]\n",
      "train-AUC: 0.7597 - val-AUC: 0.6154                                                                                                    \n",
      "Epoch 18/20\n",
      "4707/4707 [==============================] - 1s 220us/step - loss: 0.4743 - acc: 0.7994 - auc: 0.8374\n",
      "[[0.93580914 0.06419085]\n",
      " [0.9116785  0.0883215 ]\n",
      " [0.71180147 0.28819856]\n",
      " ...\n",
      " [0.7457434  0.25425655]\n",
      " [0.91722614 0.08277386]\n",
      " [0.78195524 0.21804479]]\n",
      "train-AUC: 0.7554 - val-AUC: 0.6151                                                                                                    \n",
      "Epoch 19/20\n",
      "4707/4707 [==============================] - 1s 227us/step - loss: 0.4732 - acc: 0.7956 - auc: 0.8382\n",
      "[[0.9257523  0.07424776]\n",
      " [0.92969835 0.07030161]\n",
      " [0.7014817  0.2985183 ]\n",
      " ...\n",
      " [0.67691916 0.32308087]\n",
      " [0.9279519  0.07204808]\n",
      " [0.78669226 0.2133078 ]]\n",
      "train-AUC: 0.7715 - val-AUC: 0.6109                                                                                                    \n",
      "Epoch 20/20\n",
      "4707/4707 [==============================] - 1s 224us/step - loss: 0.4727 - acc: 0.7912 - auc: 0.8390\n",
      "[[0.9759537  0.02404627]\n",
      " [0.91518027 0.08481979]\n",
      " [0.7322466  0.26775345]\n",
      " ...\n",
      " [0.7587933  0.24120669]\n",
      " [0.93435484 0.06564513]\n",
      " [0.8713328  0.12866715]]\n",
      "train-AUC: 0.7666 - val-AUC: 0.6287                                                                                                    \n",
      "\n",
      "Fold  3\n",
      "Epoch 1/20\n",
      "4708/4708 [==============================] - 26s 5ms/step - loss: 0.6067 - acc: 0.7298 - auc: 0.7297\n",
      "[[0.68291664 0.31708336]\n",
      " [0.81948745 0.18051255]\n",
      " [0.6073429  0.3926571 ]\n",
      " ...\n",
      " [0.71113867 0.28886136]\n",
      " [0.9278556  0.0721444 ]\n",
      " [0.77770317 0.22229685]]\n",
      "train-AUC: 0.635 - val-AUC: 0.5875                                                                                                    \n",
      "Epoch 2/20\n",
      "4708/4708 [==============================] - 1s 208us/step - loss: 0.5276 - acc: 0.7799 - auc: 0.7848\n",
      "[[0.6895526  0.31044742]\n",
      " [0.8427204  0.15727964]\n",
      " [0.6318906  0.36810943]\n",
      " ...\n",
      " [0.7086296  0.29137033]\n",
      " [0.91034627 0.08965374]\n",
      " [0.80990046 0.19009958]]\n",
      "train-AUC: 0.6573 - val-AUC: 0.604                                                                                                    \n",
      "Epoch 3/20\n",
      "4708/4708 [==============================] - 1s 210us/step - loss: 0.5200 - acc: 0.7855 - auc: 0.8014\n",
      "[[0.7080421  0.29195786]\n",
      " [0.80853623 0.19146378]\n",
      " [0.6054196  0.39458045]\n",
      " ...\n",
      " [0.8515367  0.14846334]\n",
      " [0.91626585 0.08373421]\n",
      " [0.76749104 0.23250896]]\n",
      "train-AUC: 0.6607 - val-AUC: 0.5887                                                                                                    \n",
      "Epoch 4/20\n",
      "4708/4708 [==============================] - 1s 217us/step - loss: 0.5122 - acc: 0.7859 - auc: 0.8062\n",
      "[[0.74141306 0.25858697]\n",
      " [0.82448256 0.17551744]\n",
      " [0.65694416 0.34305584]\n",
      " ...\n",
      " [0.78929937 0.21070065]\n",
      " [0.91011596 0.08988409]\n",
      " [0.76983356 0.23016639]]\n",
      "train-AUC: 0.671 - val-AUC: 0.5979                                                                                                    \n",
      "Epoch 5/20\n",
      "4708/4708 [==============================] - 1s 215us/step - loss: 0.5081 - acc: 0.7874 - auc: 0.8107\n",
      "[[0.7724075  0.22759248]\n",
      " [0.84567356 0.15432642]\n",
      " [0.670888   0.32911196]\n",
      " ...\n",
      " [0.8632788  0.1367212 ]\n",
      " [0.9262145  0.07378548]\n",
      " [0.8199016  0.18009847]]\n",
      "train-AUC: 0.6735 - val-AUC: 0.5992                                                                                                    \n",
      "Epoch 6/20\n",
      "4708/4708 [==============================] - 1s 218us/step - loss: 0.5008 - acc: 0.7876 - auc: 0.8141\n",
      "[[0.67997    0.32003   ]\n",
      " [0.8159569  0.18404314]\n",
      " [0.6427318  0.3572682 ]\n",
      " ...\n",
      " [0.84169006 0.1583099 ]\n",
      " [0.887629   0.11237098]\n",
      " [0.7539348  0.24606518]]\n",
      "train-AUC: 0.6913 - val-AUC: 0.6195                                                                                                    \n",
      "Epoch 7/20\n",
      "4708/4708 [==============================] - 1s 217us/step - loss: 0.5028 - acc: 0.7882 - auc: 0.8174\n",
      "[[0.7119798  0.2880202 ]\n",
      " [0.74760735 0.2523927 ]\n",
      " [0.73331565 0.26668435]\n",
      " ...\n",
      " [0.817463   0.182537  ]\n",
      " [0.8545793  0.14542067]\n",
      " [0.7457441  0.2542559 ]]\n",
      "train-AUC: 0.6862 - val-AUC: 0.6197                                                                                                    \n",
      "Epoch 8/20\n",
      "4708/4708 [==============================] - 1s 211us/step - loss: 0.5006 - acc: 0.7880 - auc: 0.8190\n",
      "[[0.6610253  0.33897474]\n",
      " [0.7717381  0.22826184]\n",
      " [0.6461923  0.35380772]\n",
      " ...\n",
      " [0.8499165  0.15008354]\n",
      " [0.88997054 0.11002945]\n",
      " [0.7894123  0.21058771]]\n",
      "train-AUC: 0.6944 - val-AUC: 0.6216                                                                                                    \n",
      "Epoch 9/20\n",
      "4708/4708 [==============================] - 1s 216us/step - loss: 0.4969 - acc: 0.7884 - auc: 0.8205\n",
      "[[0.78683496 0.213165  ]\n",
      " [0.7697301  0.23026991]\n",
      " [0.6818369  0.31816307]\n",
      " ...\n",
      " [0.8473327  0.1526673 ]\n",
      " [0.90566987 0.09433015]\n",
      " [0.778766   0.221234  ]]\n",
      "train-AUC: 0.7001 - val-AUC: 0.6317                                                                                                    \n",
      "Epoch 10/20\n",
      "4708/4708 [==============================] - 1s 226us/step - loss: 0.4966 - acc: 0.7878 - auc: 0.8225\n",
      "[[0.6531546  0.34684548]\n",
      " [0.8069074  0.19309254]\n",
      " [0.65653235 0.34346762]\n",
      " ...\n",
      " [0.8030751  0.19692494]\n",
      " [0.8985544  0.10144562]\n",
      " [0.71459454 0.28540552]]\n",
      "train-AUC: 0.7005 - val-AUC: 0.6134                                                                                                    \n",
      "Epoch 11/20\n",
      "4708/4708 [==============================] - 1s 241us/step - loss: 0.4934 - acc: 0.7889 - auc: 0.8232\n",
      "[[0.7358227  0.2641773 ]\n",
      " [0.7964141  0.20358592]\n",
      " [0.65593404 0.344066  ]\n",
      " ...\n",
      " [0.90641326 0.0935868 ]\n",
      " [0.93681616 0.06318384]\n",
      " [0.7742615  0.22573856]]\n",
      "train-AUC: 0.706 - val-AUC: 0.6194                                                                                                    \n",
      "Epoch 12/20\n",
      "4708/4708 [==============================] - 1s 228us/step - loss: 0.4864 - acc: 0.7889 - auc: 0.8251\n",
      "[[0.7224819  0.2775181 ]\n",
      " [0.718733   0.281267  ]\n",
      " [0.6821464  0.31785366]\n",
      " ...\n",
      " [0.85367435 0.1463256 ]\n",
      " [0.9295853  0.07041473]\n",
      " [0.7432978  0.2567022 ]]\n",
      "train-AUC: 0.7068 - val-AUC: 0.6273                                                                                                    \n",
      "Epoch 13/20\n",
      "4708/4708 [==============================] - 1s 219us/step - loss: 0.4876 - acc: 0.7891 - auc: 0.8262\n",
      "[[0.6503685  0.34963143]\n",
      " [0.7532608  0.24673925]\n",
      " [0.67578816 0.3242118 ]\n",
      " ...\n",
      " [0.85562766 0.14437233]\n",
      " [0.9338006  0.06619946]\n",
      " [0.7553782  0.24462178]]\n",
      "train-AUC: 0.7244 - val-AUC: 0.6238                                                                                                    \n",
      "Epoch 14/20\n",
      "4708/4708 [==============================] - 1s 218us/step - loss: 0.4876 - acc: 0.7897 - auc: 0.8274\n",
      "[[0.7359759  0.2640241 ]\n",
      " [0.8068959  0.193104  ]\n",
      " [0.6768525  0.3231475 ]\n",
      " ...\n",
      " [0.86289775 0.13710228]\n",
      " [0.9488669  0.05113307]\n",
      " [0.8135045  0.18649547]]\n",
      "train-AUC: 0.7149 - val-AUC: 0.6401                                                                                                    \n",
      "Epoch 15/20\n",
      "4708/4708 [==============================] - 1s 220us/step - loss: 0.4810 - acc: 0.7895 - auc: 0.8287\n",
      "[[0.6635613  0.33643872]\n",
      " [0.82373416 0.17626584]\n",
      " [0.68671364 0.31328633]\n",
      " ...\n",
      " [0.8811547  0.11884527]\n",
      " [0.94296986 0.05703011]\n",
      " [0.6989096  0.3010904 ]]\n",
      "train-AUC: 0.7278 - val-AUC: 0.6389                                                                                                    \n",
      "Epoch 16/20\n",
      "4708/4708 [==============================] - 1s 217us/step - loss: 0.4827 - acc: 0.7891 - auc: 0.8300\n",
      "[[0.64571506 0.354285  ]\n",
      " [0.8147897  0.18521029]\n",
      " [0.68515927 0.3148407 ]\n",
      " ...\n",
      " [0.8321564  0.16784358]\n",
      " [0.94486403 0.05513593]\n",
      " [0.70383686 0.2961631 ]]\n",
      "train-AUC: 0.7371 - val-AUC: 0.6494                                                                                                    \n",
      "Epoch 17/20\n",
      "4708/4708 [==============================] - 1s 222us/step - loss: 0.4786 - acc: 0.7893 - auc: 0.8312\n",
      "[[0.63680845 0.3631915 ]\n",
      " [0.8327295  0.16727051]\n",
      " [0.7196947  0.2803053 ]\n",
      " ...\n",
      " [0.8658867  0.13411331]\n",
      " [0.9093908  0.09060923]\n",
      " [0.7181095  0.28189057]]\n",
      "train-AUC: 0.7336 - val-AUC: 0.6352                                                                                                    \n",
      "Epoch 18/20\n",
      "4708/4708 [==============================] - 1s 218us/step - loss: 0.4816 - acc: 0.7912 - auc: 0.8322\n",
      "[[0.63919985 0.36080015]\n",
      " [0.8100548  0.18994525]\n",
      " [0.7458721  0.25412786]\n",
      " ...\n",
      " [0.7748002  0.22519979]\n",
      " [0.92901224 0.07098772]\n",
      " [0.6890121  0.31098792]]\n",
      "train-AUC: 0.7432 - val-AUC: 0.6469                                                                                                    \n",
      "Epoch 19/20\n",
      "4708/4708 [==============================] - 1s 223us/step - loss: 0.4748 - acc: 0.7912 - auc: 0.8332\n",
      "[[0.6876608  0.31233913]\n",
      " [0.7983953  0.20160477]\n",
      " [0.71961325 0.28038678]\n",
      " ...\n",
      " [0.8483089  0.15169108]\n",
      " [0.92706585 0.07293421]\n",
      " [0.73263264 0.26736733]]\n",
      "train-AUC: 0.7412 - val-AUC: 0.6394                                                                                                    \n",
      "Epoch 20/20\n",
      "4708/4708 [==============================] - 1s 227us/step - loss: 0.4742 - acc: 0.7918 - auc: 0.8344\n",
      "[[0.649777   0.35022303]\n",
      " [0.8159769  0.1840231 ]\n",
      " [0.7305273  0.26947272]\n",
      " ...\n",
      " [0.8450334  0.15496655]\n",
      " [0.9228855  0.07711453]\n",
      " [0.704717   0.295283  ]]\n",
      "train-AUC: 0.7494 - val-AUC: 0.6499                                                                                                    \n",
      "\n",
      "Fold  4\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4708/4708 [==============================] - 28s 6ms/step - loss: 0.6234 - acc: 0.7203 - auc: 0.6847\n",
      "[[0.78730166 0.21269828]\n",
      " [0.70715845 0.29284152]\n",
      " [0.74337023 0.2566298 ]\n",
      " ...\n",
      " [0.6550964  0.34490356]\n",
      " [0.64140886 0.3585912 ]\n",
      " [0.67298746 0.32701257]]\n",
      "train-AUC: 0.6248 - val-AUC: 0.605                                                                                                    \n",
      "Epoch 2/20\n",
      "4708/4708 [==============================] - 1s 212us/step - loss: 0.5378 - acc: 0.7770 - auc: 0.7718\n",
      "[[0.79770625 0.20229374]\n",
      " [0.7614539  0.2385461 ]\n",
      " [0.79580384 0.20419613]\n",
      " ...\n",
      " [0.65990156 0.34009844]\n",
      " [0.7173675  0.28263253]\n",
      " [0.77367824 0.22632179]]\n",
      "train-AUC: 0.6505 - val-AUC: 0.6036                                                                                                    \n",
      "Epoch 3/20\n",
      "4708/4708 [==============================] - 1s 208us/step - loss: 0.5183 - acc: 0.7880 - auc: 0.7898\n",
      "[[0.7869986  0.21300142]\n",
      " [0.7609369  0.2390631 ]\n",
      " [0.7835576  0.21644238]\n",
      " ...\n",
      " [0.6662996  0.33370042]\n",
      " [0.77421784 0.22578213]\n",
      " [0.7481982  0.2518018 ]]\n",
      "train-AUC: 0.6587 - val-AUC: 0.6285                                                                                                    \n",
      "Epoch 4/20\n",
      "4708/4708 [==============================] - 1s 216us/step - loss: 0.5133 - acc: 0.7874 - auc: 0.8001\n",
      "[[0.8579709  0.14202915]\n",
      " [0.75062335 0.2493766 ]\n",
      " [0.7921156  0.20788439]\n",
      " ...\n",
      " [0.7005784  0.29942158]\n",
      " [0.735677   0.26432297]\n",
      " [0.72544104 0.27455893]]\n",
      "train-AUC: 0.6664 - val-AUC: 0.622                                                                                                    \n",
      "Epoch 5/20\n",
      "4708/4708 [==============================] - 1s 225us/step - loss: 0.5066 - acc: 0.7889 - auc: 0.8057\n",
      "[[0.8921004  0.10789961]\n",
      " [0.7293269  0.27067307]\n",
      " [0.7806482  0.21935177]\n",
      " ...\n",
      " [0.64516103 0.35483903]\n",
      " [0.73067826 0.2693217 ]\n",
      " [0.7009592  0.29904082]]\n",
      "train-AUC: 0.6733 - val-AUC: 0.6181                                                                                                    \n",
      "Epoch 6/20\n",
      "4708/4708 [==============================] - 1s 214us/step - loss: 0.5099 - acc: 0.7897 - auc: 0.8087\n",
      "[[0.8907936  0.10920634]\n",
      " [0.763456   0.23654401]\n",
      " [0.6916528  0.30834725]\n",
      " ...\n",
      " [0.6824935  0.31750655]\n",
      " [0.7328908  0.26710916]\n",
      " [0.77957463 0.22042537]]\n",
      "train-AUC: 0.6757 - val-AUC: 0.6185                                                                                                    \n",
      "Epoch 7/20\n",
      "4708/4708 [==============================] - 1s 217us/step - loss: 0.4996 - acc: 0.7901 - auc: 0.8122\n",
      "[[0.8968697  0.10313025]\n",
      " [0.7220295  0.27797055]\n",
      " [0.7983755  0.2016245 ]\n",
      " ...\n",
      " [0.66730446 0.3326956 ]\n",
      " [0.68858343 0.31141654]\n",
      " [0.7333969  0.26660317]]\n",
      "train-AUC: 0.6823 - val-AUC: 0.6174                                                                                                    \n",
      "Epoch 8/20\n",
      "4708/4708 [==============================] - 1s 276us/step - loss: 0.4989 - acc: 0.7912 - auc: 0.8148\n",
      "[[0.8931834  0.10681655]\n",
      " [0.7462556  0.25374445]\n",
      " [0.85631955 0.14368048]\n",
      " ...\n",
      " [0.6345386  0.36546135]\n",
      " [0.7067519  0.2932481 ]\n",
      " [0.7144004  0.28559956]]\n",
      "train-AUC: 0.6852 - val-AUC: 0.6228                                                                                                    \n",
      "Epoch 9/20\n",
      "4708/4708 [==============================] - 1s 254us/step - loss: 0.4999 - acc: 0.7901 - auc: 0.8173\n",
      "[[0.8631349  0.13686505]\n",
      " [0.71953475 0.28046525]\n",
      " [0.82259643 0.17740357]\n",
      " ...\n",
      " [0.6596805  0.3403195 ]\n",
      " [0.72172666 0.27827337]\n",
      " [0.74677426 0.25322577]]\n",
      "train-AUC: 0.6844 - val-AUC: 0.6316                                                                                                    \n",
      "Epoch 10/20\n",
      "4708/4708 [==============================] - 1s 230us/step - loss: 0.4991 - acc: 0.7901 - auc: 0.8187\n",
      "[[0.8769121  0.12308787]\n",
      " [0.73441327 0.2655867 ]\n",
      " [0.8965571  0.10344291]\n",
      " ...\n",
      " [0.6414385  0.3585615 ]\n",
      " [0.7200657  0.27993426]\n",
      " [0.7573967  0.24260324]]\n",
      "train-AUC: 0.6911 - val-AUC: 0.6318                                                                                                    \n",
      "Epoch 11/20\n",
      "4708/4708 [==============================] - 1s 216us/step - loss: 0.4956 - acc: 0.7908 - auc: 0.8202\n",
      "[[0.8817565  0.11824354]\n",
      " [0.7385815  0.26141858]\n",
      " [0.890254   0.10974602]\n",
      " ...\n",
      " [0.6258472  0.37415284]\n",
      " [0.71976155 0.2802384 ]\n",
      " [0.71900374 0.2809962 ]]\n",
      "train-AUC: 0.6921 - val-AUC: 0.6225                                                                                                    \n",
      "Epoch 12/20\n",
      "4708/4708 [==============================] - 1s 220us/step - loss: 0.4894 - acc: 0.7906 - auc: 0.8219\n",
      "[[0.9067767  0.0932233 ]\n",
      " [0.7153573  0.2846427 ]\n",
      " [0.84864604 0.15135393]\n",
      " ...\n",
      " [0.6268681  0.37313184]\n",
      " [0.7578914  0.24210858]\n",
      " [0.778823   0.221177  ]]\n",
      "train-AUC: 0.6988 - val-AUC: 0.6361                                                                                                    \n",
      "Epoch 13/20\n",
      "4708/4708 [==============================] - 1s 220us/step - loss: 0.4943 - acc: 0.7908 - auc: 0.8234\n",
      "[[0.91122913 0.08877087]\n",
      " [0.7394027  0.26059735]\n",
      " [0.8906898  0.10931023]\n",
      " ...\n",
      " [0.63991034 0.3600897 ]\n",
      " [0.7253653  0.27463472]\n",
      " [0.71858484 0.28141513]]\n",
      "train-AUC: 0.7082 - val-AUC: 0.6273                                                                                                    \n",
      "Epoch 14/20\n",
      "4708/4708 [==============================] - 1s 226us/step - loss: 0.4928 - acc: 0.7891 - auc: 0.8244\n",
      "[[0.9420382  0.05796176]\n",
      " [0.7210422  0.27895784]\n",
      " [0.8372572  0.16274281]\n",
      " ...\n",
      " [0.6502389  0.3497611 ]\n",
      " [0.7768958  0.2231042 ]\n",
      " [0.7637529  0.23624712]]\n",
      "train-AUC: 0.7004 - val-AUC: 0.6269                                                                                                    \n",
      "Epoch 15/20\n",
      "4708/4708 [==============================] - 1s 223us/step - loss: 0.4857 - acc: 0.7912 - auc: 0.8256\n",
      "[[0.94080293 0.05919713]\n",
      " [0.7352168  0.26478326]\n",
      " [0.8771826  0.12281733]\n",
      " ...\n",
      " [0.6330265  0.36697352]\n",
      " [0.802057   0.19794299]\n",
      " [0.759782   0.24021803]]\n",
      "train-AUC: 0.7083 - val-AUC: 0.6401                                                                                                    \n",
      "Epoch 16/20\n",
      "4708/4708 [==============================] - 1s 220us/step - loss: 0.4890 - acc: 0.7933 - auc: 0.8268\n",
      "[[0.94403565 0.05596442]\n",
      " [0.6925614  0.30743867]\n",
      " [0.8907413  0.10925863]\n",
      " ...\n",
      " [0.6400595  0.35994053]\n",
      " [0.75834066 0.24165933]\n",
      " [0.77278155 0.2272184 ]]\n",
      "train-AUC: 0.7177 - val-AUC: 0.6444                                                                                                    \n",
      "Epoch 17/20\n",
      "4708/4708 [==============================] - 1s 219us/step - loss: 0.4866 - acc: 0.7906 - auc: 0.8280\n",
      "[[0.94838774 0.05161227]\n",
      " [0.66580313 0.33419684]\n",
      " [0.8347513  0.16524863]\n",
      " ...\n",
      " [0.66031617 0.3396838 ]\n",
      " [0.734705   0.26529503]\n",
      " [0.7234046  0.2765954 ]]\n",
      "train-AUC: 0.7173 - val-AUC: 0.6357                                                                                                    \n",
      "Epoch 18/20\n",
      "4708/4708 [==============================] - 1s 222us/step - loss: 0.4832 - acc: 0.7916 - auc: 0.8289\n",
      "[[0.933341   0.06665894]\n",
      " [0.6899833  0.31001666]\n",
      " [0.8299754  0.17002459]\n",
      " ...\n",
      " [0.6304544  0.36954564]\n",
      " [0.73398614 0.2660139 ]\n",
      " [0.7005029  0.29949716]]\n",
      "train-AUC: 0.7184 - val-AUC: 0.6285                                                                                                    \n",
      "Epoch 19/20\n",
      "4708/4708 [==============================] - 1s 226us/step - loss: 0.4864 - acc: 0.7918 - auc: 0.8298\n",
      "[[0.93739635 0.06260362]\n",
      " [0.68137646 0.31862357]\n",
      " [0.8522205  0.1477795 ]\n",
      " ...\n",
      " [0.62280226 0.37719774]\n",
      " [0.7364714  0.2635286 ]\n",
      " [0.7392798  0.26072016]]\n",
      "train-AUC: 0.7261 - val-AUC: 0.6384                                                                                                    \n",
      "Epoch 20/20\n",
      "4708/4708 [==============================] - 1s 221us/step - loss: 0.4786 - acc: 0.7935 - auc: 0.8305\n",
      "[[0.94849765 0.05150238]\n",
      " [0.74038917 0.25961077]\n",
      " [0.8273822  0.17261776]\n",
      " ...\n",
      " [0.6326377  0.36736232]\n",
      " [0.7737522  0.2262478 ]\n",
      " [0.75203824 0.24796177]]\n",
      "train-AUC: 0.7218 - val-AUC: 0.6281                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "folds = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=1).split(peptides, labels))\n",
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    print('\\nFold ',j)\n",
    "    X_train_cv = [peptides[train_idx], affinity[train_idx]]\n",
    "    y_train_cv = labels[train_idx]\n",
    "    X_valid_cv = [peptides[val_idx], affinity[val_idx]]\n",
    "    y_valid_cv = labels[val_idx]\n",
    "    model = get_model()\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train_cv),\n",
    "                                                 y_train_cv.ravel())\n",
    "    model.fit(X_train_cv, to_categorical(y_train_cv), batch_size=128, class_weight=class_weights, epochs=20, callbacks=[roc_callback(training_data=(X_train_cv, to_categorical(y_train_cv)),validation_data=(X_valid_cv, to_categorical(y_valid_cv)))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape=(11, 31,), name = 'main_input')\n",
    "side_input = Input(shape=(6,), name = 'side_input')\n",
    "\n",
    "# Main block for peptides.\n",
    "a = Bidirectional(LSTM(64, return_sequences=True))(main_input)\n",
    "a = Bidirectional(LSTM(32, return_sequences=True))(a)\n",
    "a = TimeDistributed(Dense(32))(a)\n",
    "a = Flatten()(a)\n",
    "a = Dense(32)(a)\n",
    "\n",
    "b = Dense(6)(side_input)\n",
    "\n",
    "merged = concatenate([a, b], axis=-1)\n",
    "\n",
    "c = Dense(32)(merged)\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(c)\n",
    "\n",
    "model = Model(inputs=[main_input, side_input], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5884/5884 [==============================] - 10s 2ms/step - loss: 0.5174 - auc: 0.5438\n",
      "Epoch 2/10\n",
      "5884/5884 [==============================] - 4s 640us/step - loss: 0.4973 - auc: 0.6026\n",
      "Epoch 3/10\n",
      "5884/5884 [==============================] - 4s 635us/step - loss: 0.4939 - auc: 0.6196\n",
      "Epoch 4/10\n",
      "5884/5884 [==============================] - 4s 612us/step - loss: 0.4889 - auc: 0.6295\n",
      "Epoch 5/10\n",
      "5884/5884 [==============================] - 4s 635us/step - loss: 0.4861 - auc: 0.6387\n",
      "Epoch 6/10\n",
      "5884/5884 [==============================] - 4s 665us/step - loss: 0.4843 - auc: 0.6432\n",
      "Epoch 7/10\n",
      "5884/5884 [==============================] - 4s 703us/step - loss: 0.4810 - auc: 0.6496\n",
      "Epoch 8/10\n",
      "5884/5884 [==============================] - 4s 642us/step - loss: 0.4774 - auc: 0.6547\n",
      "Epoch 9/10\n",
      "5884/5884 [==============================] - 4s 631us/step - loss: 0.4772 - auc: 0.6586\n",
      "Epoch 10/10\n",
      "5884/5884 [==============================] - 4s 633us/step - loss: 0.4783 - auc: 0.6615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6a37cb2c88>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([peptides, mhc], labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
